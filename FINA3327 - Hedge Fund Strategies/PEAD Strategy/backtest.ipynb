{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import wrds\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRDS recommends setting up a .pgpass file.\n",
      "Created .pgpass file successfully.\n",
      "You can create this file yourself at any time with the create_pgpass_file() function.\n",
      "Loading library list...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "conn = wrds.Connection()\n",
    "\n",
    "# set sample date range\n",
    "begdate = '01/01/1980'\n",
    "enddate = '10/31/2023'\n",
    "\n",
    "# set CRSP date range a bit wider to guarantee collecting all information\n",
    "crsp_begdate = '01/01/1979'\n",
    "crsp_enddate = '11/20/2023'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "# Step 0: Read in ICLINK output #\n",
    "#################################\n",
    "\n",
    "# iclink.csv is the output from the python program iclink\n",
    "# it contains the linking between crsp and ibes\n",
    "# read iclink\n",
    "iclink = pd.read_csv('iclink.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benkan45d6/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:560: FutureWarning: Comparison of Timestamp with datetime.date is deprecated in order to match the standard library behavior. In a future version these will be considered non-comparable. Use 'ts == pd.Timestamp(date)' or 'ts.date() == date' instead.\n",
      "  uniques, codes = table.factorize(\n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "# Step 1. S&P 500 Index Universe #\n",
    "##################################\n",
    "\n",
    "# All companies that were ever included in S&P 500 index as an example\n",
    "# Old version of the code uses comp.idxcst_his\n",
    "\n",
    "# New code uses crsp.msp500list\n",
    "# Linking Compustat GVKEY and IBES Tickers using ICLINK               \n",
    "# For unmatched GVKEYs, use header IBTIC link in Compustat Security file \n",
    "\n",
    "\n",
    "sp500 = conn.raw_sql(f\"\"\"\n",
    "                        select a.*\n",
    "                        from crsp.msp500list as a;\n",
    "                        \"\"\", date_cols=['start', 'ending'])\n",
    "\n",
    "# CCM data\n",
    "_ccm = conn.raw_sql(\"\"\" select gvkey, lpermco as permco, lpermno as permno, \n",
    "                        linkdt, linkenddt \n",
    "                        from crsp.ccmxpf_linktable \n",
    "                        where usedflag=1 \n",
    "                        and linkprim in ('P', 'C')\"\"\", date_cols=['linkdt', 'linkenddt'])\n",
    "\n",
    "_ccm[['permco', 'permno']] = _ccm[['permco', 'permno']].astype(int)\n",
    "\n",
    "# Fill linkenddt missing value (.E in SAS dataset) with today's date\n",
    "_ccm['linkenddt'] = _ccm.linkenddt.fillna(datetime.date.today())\n",
    "\n",
    "_sec = conn.raw_sql(\"\"\" select ibtic, gvkey from comp.security \"\"\")\n",
    "\n",
    "\n",
    "# Start the sequence of left join\n",
    "gvkey = pd.merge(sp500, _ccm, how='left', on=['permno'])\n",
    "gvkey = pd.merge(gvkey, _sec.loc[_sec.ibtic.notna()], how='left', on=['gvkey'])\n",
    "\n",
    "# high quality links from iclink\n",
    "# score = 0 or 1\n",
    "iclink_hq = iclink.loc[(iclink.score <=1)]\n",
    "\n",
    "gvkey = pd.merge(gvkey, iclink_hq, how='left', on=['permno'])\n",
    "\n",
    "# fill missing ticker with ibtic\n",
    "gvkey.ticker = np.where(gvkey.ticker.notnull(), gvkey.ticker, gvkey.ibtic)\n",
    "\n",
    "# Keep relevant columns and drop duplicates if there is any\n",
    "gvkey = gvkey[['gvkey', 'permco', 'permno', 'linkdt', 'linkenddt','ticker']]\n",
    "\n",
    "gvkey = gvkey.drop_duplicates()\n",
    "\n",
    "# date ranges from gvkey\n",
    "# min linkdt for ticker and permno combination\n",
    "gvkey_mindt = gvkey.groupby(['ticker','permno']).linkdt.min().reset_index()\n",
    "\n",
    "# max linkenddt for ticker and permno combination\n",
    "gvkey_maxdt = gvkey.groupby(['ticker','permno']).linkenddt.max().reset_index()\n",
    "\n",
    "# link date range \n",
    "gvkey_dt = pd.merge(gvkey_mindt, gvkey_maxdt, how='inner', on=['ticker','permno'])\n",
    "\n",
    "\n",
    "# null unused dataframes to free memory\n",
    "sp500 = None\n",
    "_ccm = None\n",
    "_sec = None\n",
    "iclink = None\n",
    "gvkey_mindt = None\n",
    "gvkey_maxdt = None\n",
    "\n",
    "#######################################\n",
    "# Only gvkey is left                  #\n",
    "#######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "# Step 2. Extract Estimates from IBES #\n",
    "#######################################\n",
    "\n",
    "# Extract estimates from IBES Unadjusted file and select    \n",
    "# the latest estimate for a firm within broker-analyst group\n",
    "# \"fpi in (6,7)\" selects quarterly forecast for the current \n",
    "# and the next fiscal quarter    \n",
    "\n",
    "ibes_temp = conn.raw_sql(f\"\"\"\n",
    "                        select ticker, estimator, analys, pdf, fpi, value, \n",
    "                        fpedats, revdats, revtims, anndats, anntims\n",
    "                        from ibes.detu_epsus \n",
    "                        where fpedats between '{begdate}' and '{enddate}'\n",
    "                        and (fpi='6' or fpi='7')\n",
    "                        \"\"\", date_cols = ['revdats', 'anndats', 'fpedats'])\n",
    "\n",
    "\n",
    "# merge to get date range linkdt and linkenddt to fulfill date requirement\n",
    "ibes_temp = pd.merge(ibes_temp, gvkey_dt, how='left', on=['ticker'])\n",
    "ibes_temp = ibes_temp.loc[(ibes_temp.linkdt<=ibes_temp.anndats) & (ibes_temp.anndats <= ibes_temp.linkenddt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of estimates reported on primary/diluted basis \n",
    "\n",
    "p_sub = ibes_temp[['ticker','fpedats','pdf']].loc[ibes_temp.pdf=='P']\n",
    "d_sub = ibes_temp[['ticker','fpedats','pdf']].loc[ibes_temp.pdf=='D']\n",
    "\n",
    "p_count = p_sub.groupby(['ticker','fpedats']).pdf.count().reset_index().rename(columns={'pdf':'p_count'})\n",
    "d_count = d_sub.groupby(['ticker','fpedats']).pdf.count().reset_index().rename(columns={'pdf':'d_count'})\n",
    "\n",
    "ibes = pd.merge(ibes_temp, d_count, how = 'left', on=['ticker', 'fpedats'])\n",
    "ibes = pd.merge(ibes, p_count, how='left', on =['ticker','fpedats'])\n",
    "ibes['d_count'] = ibes.d_count.fillna(0)\n",
    "ibes['p_count'] = ibes.p_count.fillna(0)\n",
    "\n",
    "# Determine whether most analysts report estimates on primary/diluted basis\n",
    "# following Livnat and Mendenhall (2006)                                   \n",
    "\n",
    "ibes['basis']=np.where(ibes.p_count>ibes.d_count, 'P', 'D')\n",
    "\n",
    "ibes = ibes.sort_values(by=['ticker','fpedats','estimator','analys','anndats', 'anntims', 'revdats', 'revtims'])\\\n",
    ".drop(['linkdt', 'linkenddt','p_count','d_count', 'pdf', 'fpi'], axis=1)\n",
    "\n",
    "# Keep the latest observation for a given analyst\n",
    "# Group by company fpedats estimator analys then pick the last record in the group\n",
    "\n",
    "ibes_1 = ibes.groupby(['ticker','fpedats','estimator','analys']).apply(lambda x: x.index[-1]).to_frame().reset_index()\n",
    "\n",
    "# reset index to the old dataframe index for join in the next step\n",
    "ibes_1=ibes_1.set_index(0)\n",
    "\n",
    "# Inner join with the last analyst record per group\n",
    "ibes = pd.merge(ibes, ibes_1[['analys']], left_index=True, right_index=True)\n",
    "\n",
    "# drop duplicate column\n",
    "ibes=ibes.drop(['analys_y'], axis=1).rename(columns={'analys_x': 'analys'})\n",
    "\n",
    "\n",
    "# null unneeded dataframes\n",
    "ibes_temp = None\n",
    "p_sub = None\n",
    "d_sub = None\n",
    "p_count = None\n",
    "d_count = None\n",
    "gvkey_dt = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "# Step 3. Link Estimates with Actuals #\n",
    "#######################################\n",
    "\n",
    "# Link Unadjusted estimates with Unadjusted actuals and CRSP permnos  \n",
    "# Keep only the estimates issued within 90 days before the report date\n",
    "\n",
    "# Getting actual piece of data\n",
    "ibes_act = conn.raw_sql(f\"\"\"\n",
    "                        select ticker, anndats as repdats, value as act, pends as fpedats, pdicity\n",
    "                        from ibes.actu_epsus \n",
    "                        where pends between '{begdate}' and '{enddate}'\n",
    "                        and pdicity='QTR'\n",
    "                        \"\"\", date_cols = ['repdats', 'fpedats'])\n",
    "\n",
    "\n",
    "# Join with the estimate piece of the data\n",
    "\n",
    "ibes1 = pd.merge(ibes, ibes_act, how='left', on = ['ticker','fpedats'])\n",
    "ibes1['dgap'] = ibes1.repdats - ibes1.anndats\n",
    "\n",
    "ibes1['flag'] = np.where( (ibes1.dgap>=datetime.timedelta(days=0)) & (ibes1.dgap<=datetime.timedelta(days=90)) & (ibes1.repdats.notna()) & (ibes1.anndats.notna()), 1, 0)\n",
    "\n",
    "ibes1 = ibes1.loc[ibes1.flag==1].drop(['flag', 'dgap', 'pdicity'], axis=1)\n",
    "\n",
    "# Select all relevant combinations of Permnos and Date\n",
    "\n",
    "ibes1_dt1 = ibes1[['permno', 'anndats']].drop_duplicates()\n",
    "\n",
    "ibes1_dt2 = ibes1[['permno', 'repdats']].drop_duplicates().rename(columns={'repdats':'anndats'})\n",
    "\n",
    "ibes_anndats = pd.concat([ibes1_dt1, ibes1_dt2]).drop_duplicates()\n",
    "\n",
    "# null dataframes no longer needed to free memory\n",
    "ibes1_dt1 = None\n",
    "ibes1_dt2 = None\n",
    "ibes_act = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust all estimate and earnings announcement dates to the closest\n",
    "# preceding trading date in CRSP to ensure that adjustment factors won't\n",
    "# be missing after the merge  \n",
    "\n",
    "# unique anndats from ibes\n",
    "uniq_anndats = ibes_anndats[['anndats']].drop_duplicates()\n",
    "\n",
    "# unique trade dates from crsp.dsi\n",
    "crsp_dats = conn.raw_sql(\"\"\" \n",
    "                            select date \n",
    "                            from crsp.dsi \n",
    "                         \"\"\", date_cols=['date'])\n",
    "\n",
    "# Create up to 5 days prior dates relative to anndats\n",
    "\n",
    "for i in range(0, 5):\n",
    "    uniq_anndats[i] = uniq_anndats.anndats - datetime.timedelta(days=i)\n",
    "\n",
    "# reshape (transpose) the df for later join with crsp trading dates\n",
    "\n",
    "expand_anndats = uniq_anndats.set_index('anndats').stack().reset_index().\\\n",
    "rename(columns={'level_1':'prior', 0:'prior_date'})\n",
    "\n",
    "# merge with crsp trading dates\n",
    "tradedates = pd.merge(expand_anndats, crsp_dats, how='left', left_on=['prior_date'], right_on=['date'])\n",
    "\n",
    "# create the dgap (days gap) variable for min selection\n",
    "tradedates['dgap'] = tradedates.anndats-tradedates.date\n",
    "\n",
    "# choosing the row with the smallest dgap for a given anndats\n",
    "def minDgap(g):\n",
    "    try:\n",
    "        return g['dgap'].idxmin()\n",
    "    except:\n",
    "        return\n",
    "tradedates = tradedates.loc[tradedates.groupby('anndats').apply(minDgap).dropna()]\n",
    "\n",
    "tradedates = tradedates[['anndats', 'date']]\n",
    "\n",
    "# null unneeded dataframes\n",
    "unique_anndats = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get SP500 est."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gvkey</th>\n",
       "      <th>permco</th>\n",
       "      <th>permno</th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001013</td>\n",
       "      <td>2902.0</td>\n",
       "      <td>50906.0</td>\n",
       "      <td>ADCT</td>\n",
       "      <td>1800-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001013</td>\n",
       "      <td>2902.0</td>\n",
       "      <td>50906.0</td>\n",
       "      <td>ADCT</td>\n",
       "      <td>1979-03-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001013</td>\n",
       "      <td>2902.0</td>\n",
       "      <td>50906.0</td>\n",
       "      <td>ADCT</td>\n",
       "      <td>1979-03-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001013</td>\n",
       "      <td>2902.0</td>\n",
       "      <td>50906.0</td>\n",
       "      <td>ADCT</td>\n",
       "      <td>1979-03-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001013</td>\n",
       "      <td>2902.0</td>\n",
       "      <td>50906.0</td>\n",
       "      <td>ADCT</td>\n",
       "      <td>1979-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20018406</th>\n",
       "      <td>326688</td>\n",
       "      <td>56329.0</td>\n",
       "      <td>17676.0</td>\n",
       "      <td>NVT</td>\n",
       "      <td>2023-11-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20018407</th>\n",
       "      <td>326688</td>\n",
       "      <td>56329.0</td>\n",
       "      <td>17676.0</td>\n",
       "      <td>NVT</td>\n",
       "      <td>2023-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20018408</th>\n",
       "      <td>326688</td>\n",
       "      <td>56329.0</td>\n",
       "      <td>17676.0</td>\n",
       "      <td>NVT</td>\n",
       "      <td>2023-11-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20018409</th>\n",
       "      <td>326688</td>\n",
       "      <td>56329.0</td>\n",
       "      <td>17676.0</td>\n",
       "      <td>NVT</td>\n",
       "      <td>2023-11-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20018410</th>\n",
       "      <td>326688</td>\n",
       "      <td>56329.0</td>\n",
       "      <td>17676.0</td>\n",
       "      <td>NVT</td>\n",
       "      <td>2023-11-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20018411 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           gvkey   permco   permno ticker       date\n",
       "0         001013   2902.0  50906.0   ADCT 1800-01-01\n",
       "1         001013   2902.0  50906.0   ADCT 1979-03-16\n",
       "2         001013   2902.0  50906.0   ADCT 1979-03-17\n",
       "3         001013   2902.0  50906.0   ADCT 1979-03-18\n",
       "4         001013   2902.0  50906.0   ADCT 1979-03-19\n",
       "...          ...      ...      ...    ...        ...\n",
       "20018406  326688  56329.0  17676.0    NVT 2023-11-16\n",
       "20018407  326688  56329.0  17676.0    NVT 2023-11-17\n",
       "20018408  326688  56329.0  17676.0    NVT 2023-11-18\n",
       "20018409  326688  56329.0  17676.0    NVT 2023-11-19\n",
       "20018410  326688  56329.0  17676.0    NVT 2023-11-20\n",
       "\n",
       "[20018411 rows x 5 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group = gvkey.groupby(['gvkey','permco','permno','ticker'])\n",
    "def get_date(g):\n",
    "    drange = pd.date_range('1800-01-01','1800-01-01') # dummy\n",
    "    for r in range(len(g)):\n",
    "        linkdt = g['linkdt'].iloc[r]\n",
    "        linkenddt = g['linkenddt'].iloc[r]\n",
    "        drange = drange.union(pd.date_range(linkdt,linkenddt))\n",
    "    idx = g.reindex(drange).reset_index()['index']\n",
    "    return idx\n",
    "gvkey_withDate = gvkey.groupby(['gvkey','permco','permno','ticker']).apply(get_date).reset_index()\n",
    "gvkey_withDate = gvkey_withDate.drop('level_4',axis=1)\n",
    "gvkey_withDate = gvkey_withDate.rename(columns={'index':'date'})\n",
    "gvkey_withDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "earningsEst = pd.merge(gvkey_withDate,ibes1,how='inner',left_on=['ticker','date','permno'],right_on=['ticker','anndats','permno'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "earningsEst_d = earningsEst[earningsEst['basis']=='D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vh/jb52psn93fb96vlsr5_kn4m80000gn/T/ipykernel_14317/1947643251.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  earningsEst_d['sue'] = (earningsEst_d['act'] - earningsEst_d['value'])\n"
     ]
    }
   ],
   "source": [
    "earningsEst_d['sue'] = (earningsEst_d['act'] - earningsEst_d['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gvkey</th>\n",
       "      <th>permco</th>\n",
       "      <th>permno</th>\n",
       "      <th>ticker</th>\n",
       "      <th>date</th>\n",
       "      <th>estimator</th>\n",
       "      <th>analys</th>\n",
       "      <th>value</th>\n",
       "      <th>fpedats</th>\n",
       "      <th>revdats</th>\n",
       "      <th>revtims</th>\n",
       "      <th>anndats</th>\n",
       "      <th>anntims</th>\n",
       "      <th>basis</th>\n",
       "      <th>repdats</th>\n",
       "      <th>act</th>\n",
       "      <th>sue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>001013</td>\n",
       "      <td>2902.0</td>\n",
       "      <td>50906.0</td>\n",
       "      <td>ADCT</td>\n",
       "      <td>1993-09-30</td>\n",
       "      <td>942.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1993-10-31</td>\n",
       "      <td>1995-01-26</td>\n",
       "      <td>15:00:07</td>\n",
       "      <td>1993-09-30</td>\n",
       "      <td>10:16:19</td>\n",
       "      <td>D</td>\n",
       "      <td>1993-12-17</td>\n",
       "      <td>0.37</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>001013</td>\n",
       "      <td>2902.0</td>\n",
       "      <td>50906.0</td>\n",
       "      <td>ADCT</td>\n",
       "      <td>1993-10-13</td>\n",
       "      <td>183.0</td>\n",
       "      <td>995.0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1993-10-31</td>\n",
       "      <td>1995-01-26</td>\n",
       "      <td>11:37:10</td>\n",
       "      <td>1993-10-13</td>\n",
       "      <td>14:49:37</td>\n",
       "      <td>D</td>\n",
       "      <td>1993-12-17</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>001013</td>\n",
       "      <td>2902.0</td>\n",
       "      <td>50906.0</td>\n",
       "      <td>ADCT</td>\n",
       "      <td>1993-11-01</td>\n",
       "      <td>76.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1993-10-31</td>\n",
       "      <td>1994-09-27</td>\n",
       "      <td>14:26:55</td>\n",
       "      <td>1993-11-01</td>\n",
       "      <td>13:03:01</td>\n",
       "      <td>D</td>\n",
       "      <td>1993-12-17</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>001013</td>\n",
       "      <td>2902.0</td>\n",
       "      <td>50906.0</td>\n",
       "      <td>ADCT</td>\n",
       "      <td>1998-01-12</td>\n",
       "      <td>114.0</td>\n",
       "      <td>20316.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1998-01-31</td>\n",
       "      <td>1998-01-12</td>\n",
       "      <td>14:13:41</td>\n",
       "      <td>1998-01-12</td>\n",
       "      <td>11:07:14</td>\n",
       "      <td>D</td>\n",
       "      <td>1998-02-18</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>001013</td>\n",
       "      <td>2902.0</td>\n",
       "      <td>50906.0</td>\n",
       "      <td>ADCT</td>\n",
       "      <td>1998-01-26</td>\n",
       "      <td>28.0</td>\n",
       "      <td>20575.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1998-01-31</td>\n",
       "      <td>1998-08-05</td>\n",
       "      <td>15:58:36</td>\n",
       "      <td>1998-01-26</td>\n",
       "      <td>15:29:01</td>\n",
       "      <td>D</td>\n",
       "      <td>1998-02-18</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979231</th>\n",
       "      <td>326688</td>\n",
       "      <td>56329.0</td>\n",
       "      <td>17676.0</td>\n",
       "      <td>NVT</td>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>1267.0</td>\n",
       "      <td>56596.0</td>\n",
       "      <td>0.59</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2022-10-05</td>\n",
       "      <td>16:32:25</td>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>16:47:00</td>\n",
       "      <td>D</td>\n",
       "      <td>2022-10-28</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979232</th>\n",
       "      <td>326688</td>\n",
       "      <td>56329.0</td>\n",
       "      <td>17676.0</td>\n",
       "      <td>NVT</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>449.0</td>\n",
       "      <td>114868.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2022-10-04</td>\n",
       "      <td>08:00:39</td>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>15:33:00</td>\n",
       "      <td>D</td>\n",
       "      <td>2022-10-28</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979233</th>\n",
       "      <td>326688</td>\n",
       "      <td>56329.0</td>\n",
       "      <td>17676.0</td>\n",
       "      <td>NVT</td>\n",
       "      <td>2022-10-06</td>\n",
       "      <td>3051.0</td>\n",
       "      <td>74756.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2022-10-06</td>\n",
       "      <td>10:43:53</td>\n",
       "      <td>2022-10-06</td>\n",
       "      <td>01:34:00</td>\n",
       "      <td>D</td>\n",
       "      <td>2022-10-28</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979234</th>\n",
       "      <td>326688</td>\n",
       "      <td>56329.0</td>\n",
       "      <td>17676.0</td>\n",
       "      <td>NVT</td>\n",
       "      <td>2022-10-07</td>\n",
       "      <td>4201.0</td>\n",
       "      <td>193800.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>2022-10-19</td>\n",
       "      <td>02:47:47</td>\n",
       "      <td>2022-10-07</td>\n",
       "      <td>13:51:00</td>\n",
       "      <td>D</td>\n",
       "      <td>2022-10-28</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979235</th>\n",
       "      <td>326688</td>\n",
       "      <td>56329.0</td>\n",
       "      <td>17676.0</td>\n",
       "      <td>NVT</td>\n",
       "      <td>2023-01-09</td>\n",
       "      <td>449.0</td>\n",
       "      <td>114868.0</td>\n",
       "      <td>0.59</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>2023-01-09</td>\n",
       "      <td>08:21:55</td>\n",
       "      <td>2023-01-09</td>\n",
       "      <td>08:15:00</td>\n",
       "      <td>D</td>\n",
       "      <td>2023-02-07</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>785950 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         gvkey   permco   permno ticker       date  estimator    analys  \\\n",
       "70      001013   2902.0  50906.0   ADCT 1993-09-30      942.0     129.0   \n",
       "71      001013   2902.0  50906.0   ADCT 1993-10-13      183.0     995.0   \n",
       "72      001013   2902.0  50906.0   ADCT 1993-11-01       76.0     836.0   \n",
       "170     001013   2902.0  50906.0   ADCT 1998-01-12      114.0   20316.0   \n",
       "171     001013   2902.0  50906.0   ADCT 1998-01-26       28.0   20575.0   \n",
       "...        ...      ...      ...    ...        ...        ...       ...   \n",
       "979231  326688  56329.0  17676.0    NVT 2022-07-31     1267.0   56596.0   \n",
       "979232  326688  56329.0  17676.0    NVT 2022-08-01      449.0  114868.0   \n",
       "979233  326688  56329.0  17676.0    NVT 2022-10-06     3051.0   74756.0   \n",
       "979234  326688  56329.0  17676.0    NVT 2022-10-07     4201.0  193800.0   \n",
       "979235  326688  56329.0  17676.0    NVT 2023-01-09      449.0  114868.0   \n",
       "\n",
       "        value    fpedats    revdats   revtims    anndats   anntims basis  \\\n",
       "70       0.39 1993-10-31 1995-01-26  15:00:07 1993-09-30  10:16:19     D   \n",
       "71       0.37 1993-10-31 1995-01-26  11:37:10 1993-10-13  14:49:37     D   \n",
       "72       0.37 1993-10-31 1994-09-27  14:26:55 1993-11-01  13:03:01     D   \n",
       "170      0.27 1998-01-31 1998-01-12  14:13:41 1998-01-12  11:07:14     D   \n",
       "171      0.18 1998-01-31 1998-08-05  15:58:36 1998-01-26  15:29:01     D   \n",
       "...       ...        ...        ...       ...        ...       ...   ...   \n",
       "979231   0.59 2022-09-30 2022-10-05  16:32:25 2022-07-31  16:47:00     D   \n",
       "979232   0.58 2022-09-30 2022-10-04  08:00:39 2022-08-01  15:33:00     D   \n",
       "979233   0.60 2022-09-30 2022-10-06  10:43:53 2022-10-06  01:34:00     D   \n",
       "979234   0.60 2022-09-30 2022-10-19  02:47:47 2022-10-07  13:51:00     D   \n",
       "979235   0.59 2022-12-31 2023-01-09  08:21:55 2023-01-09  08:15:00     D   \n",
       "\n",
       "          repdats   act   sue  \n",
       "70     1993-12-17  0.37 -0.02  \n",
       "71     1993-12-17  0.37  0.00  \n",
       "72     1993-12-17  0.37  0.00  \n",
       "170    1998-02-18  0.19 -0.08  \n",
       "171    1998-02-18  0.19  0.01  \n",
       "...           ...   ...   ...  \n",
       "979231 2022-10-28  0.66  0.07  \n",
       "979232 2022-10-28  0.66  0.08  \n",
       "979233 2022-10-28  0.66  0.06  \n",
       "979234 2022-10-28  0.66  0.06  \n",
       "979235 2023-02-07  0.66  0.07  \n",
       "\n",
       "[785950 rows x 17 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earningsEst_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_estSummary(g):\n",
    "    g['est_mean'] = g['value'].mean()\n",
    "    g['est_median'] = g['value'].median()\n",
    "    g['est_std'] = g['value'].std()\n",
    "    g['est_count'] = g['value'].count()\n",
    "    return g[['permno','ticker','fpedats','repdats','act','est_mean','est_median','est_std','est_count']].iloc[0]\n",
    "earningsEstSummary = earningsEst_d.groupby(['permno','ticker','fpedats','repdats']).apply(get_estSummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "earningsEstSummary['sup_mean'] = earningsEstSummary['act'] - earningsEstSummary['est_mean']\n",
    "earningsEstSummary['sup_median'] = earningsEstSummary['act'] - earningsEstSummary['est_median']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "earningsEstSummary.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "earningsEstSummary.to_csv('earningsEstSummary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
